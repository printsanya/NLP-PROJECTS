{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')\n",
    "vec_king = wv['king']\n",
    "#pre trained library by google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the delimiter as tab (\\t) since SMSSpamCollection is typically tab-separated\n",
    "# Also specify column names since the file likely doesn't have headers\n",
    "messages = pd.read_csv('SMSSpamCollection.txt', \n",
    "                      sep='\\t',  # Use tab as delimiter instead of comma\n",
    "                      names=['label', 'message'])  # Provide column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# First, download the required NLTK resource\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Now your original code will work\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "corpus = []\n",
    "for i in range(0, len(messages)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', messages['message'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [lemmatizer.lemmatize(word) for word in review]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, '', '645'], [0, '', ':) '], [0, '', ':-) :-)']]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[i,j,k] for i,j,k in zip(list(map(len,corpus)),corpus, messages['message']) if i<1]\n",
    "# remove value of x which is not str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "words = []\n",
    "for sent in corpus:\n",
    "    sent_token = sent_tokenize(sent)\n",
    "    for sent in sent_token:\n",
    "# Lowercase the text.\n",
    "#Remove punctuation and special characters.\n",
    "#Split the text into a list of tokens (words).\n",
    "#Discard words shorter than 2 characters or longer than 15 by default\n",
    "        words.append(simple_preprocess(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This creates and trains a Word2Vec model on your tokenized text.\n",
    "model=gensim.models.Word2Vec(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to',\n",
       " 'you',\n",
       " 'the',\n",
       " 'it',\n",
       " 'and',\n",
       " 'in',\n",
       " 'is',\n",
       " 'me',\n",
       " 'my',\n",
       " 'for',\n",
       " 'your',\n",
       " 'call',\n",
       " 'of',\n",
       " 'that',\n",
       " 'have',\n",
       " 'on',\n",
       " 'now',\n",
       " 'are',\n",
       " 'can',\n",
       " 'so',\n",
       " 'but',\n",
       " 'not',\n",
       " 'or',\n",
       " 'we',\n",
       " 'do',\n",
       " 'get',\n",
       " 'at',\n",
       " 'ur',\n",
       " 'will',\n",
       " 'if',\n",
       " 'be',\n",
       " 'with',\n",
       " 'no',\n",
       " 'just',\n",
       " 'this',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'go',\n",
       " 'how',\n",
       " 'up',\n",
       " 'when',\n",
       " 'ok',\n",
       " 'day',\n",
       " 'what',\n",
       " 'free',\n",
       " 'from',\n",
       " 'all',\n",
       " 'out',\n",
       " 'know',\n",
       " 'll',\n",
       " 'come',\n",
       " 'like',\n",
       " 'good',\n",
       " 'time',\n",
       " 'am',\n",
       " 'then',\n",
       " 'got',\n",
       " 'wa',\n",
       " 'there',\n",
       " 'he',\n",
       " 'love',\n",
       " 'text',\n",
       " 'only',\n",
       " 'want',\n",
       " 'send',\n",
       " 'one',\n",
       " 'need',\n",
       " 'txt',\n",
       " 'today',\n",
       " 'by',\n",
       " 'going',\n",
       " 'don',\n",
       " 'stop',\n",
       " 'home',\n",
       " 'she',\n",
       " 'about',\n",
       " 'lor',\n",
       " 'sorry',\n",
       " 'see',\n",
       " 'still',\n",
       " 'mobile',\n",
       " 'take',\n",
       " 'back',\n",
       " 'da',\n",
       " 'reply',\n",
       " 'dont',\n",
       " 'our',\n",
       " 'think',\n",
       " 'tell',\n",
       " 'week',\n",
       " 'hi',\n",
       " 'phone',\n",
       " 'they',\n",
       " 'new',\n",
       " 'please',\n",
       " 'later',\n",
       " 'pls',\n",
       " 'any',\n",
       " 'her',\n",
       " 'ha',\n",
       " 'co',\n",
       " 'did',\n",
       " 'been',\n",
       " 'msg',\n",
       " 'min',\n",
       " 'some',\n",
       " 'an',\n",
       " 'night',\n",
       " 'make',\n",
       " 'dear',\n",
       " 'who',\n",
       " 'here',\n",
       " 'message',\n",
       " 'say',\n",
       " 'well',\n",
       " 'where',\n",
       " 're',\n",
       " 'thing',\n",
       " 'much',\n",
       " 'oh',\n",
       " 'great',\n",
       " 'claim',\n",
       " 'hope',\n",
       " 'hey',\n",
       " 'him',\n",
       " 'number',\n",
       " 'give',\n",
       " 'more',\n",
       " 'too',\n",
       " 'happy',\n",
       " 'work',\n",
       " 'wat',\n",
       " 'friend',\n",
       " 'had',\n",
       " 'yes',\n",
       " 'way',\n",
       " 'www',\n",
       " 've',\n",
       " 'let',\n",
       " 'should',\n",
       " 'prize',\n",
       " 'won',\n",
       " 'right',\n",
       " 'tomorrow',\n",
       " 'already',\n",
       " 'tone',\n",
       " 'after',\n",
       " 'ask',\n",
       " 'win',\n",
       " 'said',\n",
       " 'life',\n",
       " 'amp',\n",
       " 'cash',\n",
       " 'doing',\n",
       " 'im',\n",
       " 'yeah',\n",
       " 'really',\n",
       " 'meet',\n",
       " 'babe',\n",
       " 'why',\n",
       " 'find',\n",
       " 'them',\n",
       " 'miss',\n",
       " 'morning',\n",
       " 'very',\n",
       " 'last',\n",
       " 'year',\n",
       " 'service',\n",
       " 'thanks',\n",
       " 'uk',\n",
       " 'care',\n",
       " 'com',\n",
       " 'would',\n",
       " 'anything',\n",
       " 'lol',\n",
       " 'nokia',\n",
       " 'also',\n",
       " 'every',\n",
       " 'feel',\n",
       " 'keep',\n",
       " 'sure',\n",
       " 'pick',\n",
       " 'urgent',\n",
       " 'over',\n",
       " 'sent',\n",
       " 'contact',\n",
       " 'something',\n",
       " 'buy',\n",
       " 'gud',\n",
       " 'again',\n",
       " 'cant',\n",
       " 'wait',\n",
       " 'before',\n",
       " 'place',\n",
       " 'box',\n",
       " 'first',\n",
       " 'his',\n",
       " 'even',\n",
       " 'someone',\n",
       " 'guy',\n",
       " 'help',\n",
       " 'went',\n",
       " 'wish',\n",
       " 'next',\n",
       " 'tonight',\n",
       " 'were',\n",
       " 'nice',\n",
       " 'soon',\n",
       " 'show',\n",
       " 'which',\n",
       " 'off',\n",
       " 'around',\n",
       " 'word',\n",
       " 'could',\n",
       " 'customer',\n",
       " 'money',\n",
       " 'sleep',\n",
       " 'chat',\n",
       " 'per',\n",
       " 'many',\n",
       " 'late',\n",
       " 'always',\n",
       " 'ya',\n",
       " 'gonna',\n",
       " 'sm',\n",
       " 'down',\n",
       " 'leave',\n",
       " 'wan',\n",
       " 'name',\n",
       " 'lot',\n",
       " 'end',\n",
       " 'other',\n",
       " 'dun',\n",
       " 'pm',\n",
       " 'told',\n",
       " 'st',\n",
       " 'person',\n",
       " 'waiting',\n",
       " 'hello',\n",
       " 'special',\n",
       " 'try',\n",
       " 'month',\n",
       " 'girl',\n",
       " 'hour',\n",
       " 'may',\n",
       " 'fine',\n",
       " 'best',\n",
       " 'haha',\n",
       " 'minute',\n",
       " 'heart',\n",
       " 'people',\n",
       " 'coming',\n",
       " 'done',\n",
       " 'guaranteed',\n",
       " 'yet',\n",
       " 'thk',\n",
       " 'same',\n",
       " 'th',\n",
       " 'getting',\n",
       " 'smile',\n",
       " 'ppm',\n",
       " 'use',\n",
       " 'thought',\n",
       " 'god',\n",
       " 'didn',\n",
       " 'offer',\n",
       " 'stuff',\n",
       " 'holiday',\n",
       " 'talk',\n",
       " 'start',\n",
       " 'class',\n",
       " 'man',\n",
       " 'cost',\n",
       " 'live',\n",
       " 'mean',\n",
       " 'bit',\n",
       " 'line',\n",
       " 'car',\n",
       " 'lunch',\n",
       " 'few',\n",
       " 'draw',\n",
       " 'finish',\n",
       " 'job',\n",
       " 'being',\n",
       " 'problem',\n",
       " 'never',\n",
       " 'yup',\n",
       " 'ill',\n",
       " 'better',\n",
       " 'plan',\n",
       " 'trying',\n",
       " 'house',\n",
       " 'thats',\n",
       " 'cool',\n",
       " 'hr',\n",
       " 'meeting',\n",
       " 'account',\n",
       " 'rate',\n",
       " 'mind',\n",
       " 'pobox',\n",
       " 'ready',\n",
       " 'having',\n",
       " 'dat',\n",
       " 'long',\n",
       " 'weekend',\n",
       " 'game',\n",
       " 'chance',\n",
       " 'world',\n",
       " 'real',\n",
       " 'half',\n",
       " 'enjoy',\n",
       " 'latest',\n",
       " 'wk',\n",
       " 'po',\n",
       " 'room',\n",
       " 'yo',\n",
       " 'sir',\n",
       " 'check',\n",
       " 'because',\n",
       " 'than',\n",
       " 'bt',\n",
       " 'guess',\n",
       " 'play',\n",
       " 'awarded',\n",
       " 'wanna',\n",
       " 'nothing',\n",
       " 'lar',\n",
       " 'receive',\n",
       " 'boy',\n",
       " 'voucher',\n",
       " 'eat',\n",
       " 'sweet',\n",
       " 'luv',\n",
       " 'look',\n",
       " 'camera',\n",
       " 'pic',\n",
       " 'another',\n",
       " 'liao',\n",
       " 'big',\n",
       " 'shit',\n",
       " 'dinner',\n",
       " 'into',\n",
       " 'ah',\n",
       " 'landline',\n",
       " 'birthday',\n",
       " 'xxx',\n",
       " 'jus',\n",
       " 'might',\n",
       " 'ever',\n",
       " 'quite',\n",
       " 'video',\n",
       " 'kiss',\n",
       " 'age',\n",
       " 'watching',\n",
       " 'wont',\n",
       " 'question',\n",
       " 'land',\n",
       " 'watch',\n",
       " 'dream',\n",
       " 'orange',\n",
       " 'early',\n",
       " 'thanx',\n",
       " 'worry',\n",
       " 'baby',\n",
       " 'called',\n",
       " 'speak',\n",
       " 'two',\n",
       " 'tv',\n",
       " 'aight',\n",
       " 'once',\n",
       " 'hear',\n",
       " 'fun',\n",
       " 'probably',\n",
       " 'nd',\n",
       " 'point',\n",
       " 'bed',\n",
       " 'pa',\n",
       " 'pay',\n",
       " 'doe',\n",
       " 'actually',\n",
       " 'network',\n",
       " 'princess',\n",
       " 'nite',\n",
       " 'apply',\n",
       " 'maybe',\n",
       " 'shall',\n",
       " 'bus',\n",
       " 'part',\n",
       " 'sat',\n",
       " 'left',\n",
       " 'forgot',\n",
       " 'den',\n",
       " 'bad',\n",
       " 'ringtone',\n",
       " 'remember',\n",
       " 'office',\n",
       " 'hurt',\n",
       " 'easy',\n",
       " 'reach',\n",
       " 'code',\n",
       " 'shopping',\n",
       " 'between',\n",
       " 'dunno',\n",
       " 'made',\n",
       " 'xx',\n",
       " 'dis',\n",
       " 'little',\n",
       " 'evening',\n",
       " 'didnt',\n",
       " 'award',\n",
       " 'put',\n",
       " 'true',\n",
       " 'leh',\n",
       " 'fuck',\n",
       " 'everything',\n",
       " 'wife',\n",
       " 'anyway',\n",
       " 'face',\n",
       " 'dad',\n",
       " 'looking',\n",
       " 'town',\n",
       " 'thank',\n",
       " 'afternoon',\n",
       " 'gift',\n",
       " 'school',\n",
       " 'enough',\n",
       " 'sound',\n",
       " 'those',\n",
       " 'mail',\n",
       " 'working',\n",
       " 'mate',\n",
       " 'selected',\n",
       " 'yr',\n",
       " 'movie',\n",
       " 'most',\n",
       " 'collect',\n",
       " 'pound',\n",
       " 'detail',\n",
       " 'without',\n",
       " 'asked',\n",
       " 'entry',\n",
       " 'while',\n",
       " 'missing',\n",
       " 'tmr',\n",
       " 'hav',\n",
       " 'join',\n",
       " 'price',\n",
       " 'sexy',\n",
       " 'okay',\n",
       " 'though',\n",
       " 'pain',\n",
       " 'wif',\n",
       " 'important',\n",
       " 'must',\n",
       " 'xmas',\n",
       " 'wanted',\n",
       " 'until',\n",
       " 'since',\n",
       " 'valid',\n",
       " 'came',\n",
       " 'update',\n",
       " 'mob',\n",
       " 'answer',\n",
       " 'wot',\n",
       " 'lesson',\n",
       " 'missed',\n",
       " 'wake',\n",
       " 'book',\n",
       " 'abt',\n",
       " 'run',\n",
       " 'collection',\n",
       " 'bring',\n",
       " 'able',\n",
       " 'til',\n",
       " 'wen',\n",
       " 'haven',\n",
       " 'decimal',\n",
       " 'de',\n",
       " 'test',\n",
       " 'charge',\n",
       " 'juz',\n",
       " 'plus',\n",
       " 'change',\n",
       " 'stay',\n",
       " 'date',\n",
       " 'plz',\n",
       " 'colour',\n",
       " 'away',\n",
       " 'double',\n",
       " 'weekly',\n",
       " 'havent',\n",
       " 'yesterday',\n",
       " 'saw',\n",
       " 'else',\n",
       " 'music',\n",
       " 'till',\n",
       " 'shop',\n",
       " 'dude',\n",
       " 'bored',\n",
       " 'attempt',\n",
       " 'alright',\n",
       " 'hair',\n",
       " 'lei',\n",
       " 'food',\n",
       " 'optout',\n",
       " 'trip',\n",
       " 'credit',\n",
       " 'friendship',\n",
       " 'making',\n",
       " 'drink',\n",
       " 'net',\n",
       " 'these',\n",
       " 'online',\n",
       " 'id',\n",
       " 'haf',\n",
       " 'yours',\n",
       " 'top',\n",
       " 'oso',\n",
       " 'coz',\n",
       " 'goin',\n",
       " 'tried',\n",
       " 'gr',\n",
       " 'family',\n",
       " 'address',\n",
       " 'delivery',\n",
       " 'sch',\n",
       " 'hot',\n",
       " 'player',\n",
       " 'club',\n",
       " 'either',\n",
       " 'smoke',\n",
       " 'ard',\n",
       " 'driving',\n",
       " 'feeling',\n",
       " 'national',\n",
       " 'yourself',\n",
       " 'nt',\n",
       " 'sad',\n",
       " 'order',\n",
       " 'lose',\n",
       " 'together',\n",
       " 'calling',\n",
       " 'full',\n",
       " 'wid',\n",
       " 'second',\n",
       " 'story',\n",
       " 'mom',\n",
       " 'busy',\n",
       " 'ring',\n",
       " 'beautiful',\n",
       " 'head',\n",
       " 'bonus',\n",
       " 'walk',\n",
       " 'http',\n",
       " 'brother',\n",
       " 'tot',\n",
       " 'both',\n",
       " 'si',\n",
       " 'sae',\n",
       " 'post',\n",
       " 'believe',\n",
       " 'smiling',\n",
       " 'huh',\n",
       " 'close',\n",
       " 'poly',\n",
       " 'old',\n",
       " 'eve',\n",
       " 'row',\n",
       " 'chikku',\n",
       " 'happen',\n",
       " 'noe',\n",
       " 'drive',\n",
       " 'await',\n",
       " 'set',\n",
       " 'info',\n",
       " 'hand',\n",
       " 'saying',\n",
       " 'mum',\n",
       " 'sleeping',\n",
       " 'leaving',\n",
       " 'awesome',\n",
       " 'mths',\n",
       " 'took',\n",
       " 'congrats',\n",
       " 'pub',\n",
       " 'hl',\n",
       " 'email',\n",
       " 'drop',\n",
       " 'parent',\n",
       " 'wil',\n",
       " 'rite',\n",
       " 'tomo',\n",
       " 'match',\n",
       " 'thinking',\n",
       " 'suite',\n",
       " 'started',\n",
       " 'news',\n",
       " 'simple',\n",
       " 'aft',\n",
       " 'finished',\n",
       " 'private',\n",
       " 'cause',\n",
       " 'doesn',\n",
       " 'okie',\n",
       " 'tho',\n",
       " 'unsubscribe',\n",
       " 'auction',\n",
       " 'available',\n",
       " 'tc',\n",
       " 'forget',\n",
       " 'content',\n",
       " 'everyone',\n",
       " 'company',\n",
       " 'anyone',\n",
       " 'sister',\n",
       " 'touch',\n",
       " 'break',\n",
       " 'caller',\n",
       " 'valentine',\n",
       " 'reason',\n",
       " 'mine',\n",
       " 'final',\n",
       " 'card',\n",
       " 'angry',\n",
       " 'neva',\n",
       " 'taking',\n",
       " 'gd',\n",
       " 'statement',\n",
       " 'open',\n",
       " 'dating',\n",
       " 'loving',\n",
       " 'whats',\n",
       " 'alone',\n",
       " 'found',\n",
       " 'treat',\n",
       " 'whatever',\n",
       " 'lucky',\n",
       " 'fancy',\n",
       " 'carlos',\n",
       " 'gal',\n",
       " 'choose',\n",
       " 'worth',\n",
       " 'opt',\n",
       " 'each',\n",
       " 'ticket',\n",
       " 'search',\n",
       " 'sun',\n",
       " 'knw',\n",
       " 'type',\n",
       " 'bank',\n",
       " 'expires',\n",
       " 'wonderful',\n",
       " 'frnd',\n",
       " 'hows',\n",
       " 'mobileupd',\n",
       " 'hit',\n",
       " 'winner',\n",
       " 'hard',\n",
       " 'boytoy',\n",
       " 'gone',\n",
       " 'saturday',\n",
       " 'gbp',\n",
       " 'welcome',\n",
       " 'fast',\n",
       " 'happened',\n",
       " 'quiz',\n",
       " 'anytime',\n",
       " 'kind',\n",
       " 'congratulation',\n",
       " 'bout',\n",
       " 'secret',\n",
       " 'far',\n",
       " 'identifier',\n",
       " 'decided',\n",
       " 'sub',\n",
       " 'ni',\n",
       " 'exam',\n",
       " 'uncle',\n",
       " 'ltd',\n",
       " 'party',\n",
       " 'smth',\n",
       " 'friday',\n",
       " 'college',\n",
       " 'visit',\n",
       " 'nyt',\n",
       " 'prob',\n",
       " 'song',\n",
       " 'darlin',\n",
       " 'mu',\n",
       " 'hold',\n",
       " 'read',\n",
       " 'light',\n",
       " 'operator',\n",
       " 'oredi',\n",
       " 'goodmorning',\n",
       " 'finally',\n",
       " 'mrng',\n",
       " 'tel',\n",
       " 'sea',\n",
       " 'wit',\n",
       " 'project',\n",
       " 'pretty',\n",
       " 'outside',\n",
       " 'nope',\n",
       " 'term',\n",
       " 'used',\n",
       " 'drug',\n",
       " 'fucking',\n",
       " 'wonder',\n",
       " 'camcorder',\n",
       " 'lovely',\n",
       " 'wrong',\n",
       " 'least',\n",
       " 'chennai',\n",
       " 'fri',\n",
       " 'crazy',\n",
       " 'ten',\n",
       " 'log',\n",
       " 'cum',\n",
       " 'listen',\n",
       " 'frnds',\n",
       " 'freemsg',\n",
       " 'seeing',\n",
       " 'blue',\n",
       " 'telling',\n",
       " 'fone',\n",
       " 'case',\n",
       " 'meant',\n",
       " 'jay',\n",
       " 'whole',\n",
       " 'fr',\n",
       " 'unlimited',\n",
       " 'cd',\n",
       " 'their',\n",
       " 'wasn',\n",
       " 'isn',\n",
       " 'support',\n",
       " 'course',\n",
       " 'frm',\n",
       " 'sunday',\n",
       " 'hmm',\n",
       " 'wq',\n",
       " 'savamob',\n",
       " 'snow',\n",
       " 'hungry',\n",
       " 'earlier',\n",
       " 'wkly',\n",
       " 'stupid',\n",
       " 'die',\n",
       " 'happiness',\n",
       " 'un',\n",
       " 'dnt',\n",
       " 'move',\n",
       " 'etc',\n",
       " 'hee',\n",
       " 'within',\n",
       " 'single',\n",
       " 'yar',\n",
       " 'hmmm',\n",
       " 'cut',\n",
       " 'mr',\n",
       " 'eh',\n",
       " 'moment',\n",
       " 'march',\n",
       " 'enter',\n",
       " 'joy',\n",
       " 'luck',\n",
       " 'film',\n",
       " 'na',\n",
       " 'balance',\n",
       " 'gn',\n",
       " 'john',\n",
       " 'gas',\n",
       " 'child',\n",
       " 'knew',\n",
       " 'understand',\n",
       " 'pas',\n",
       " 'father',\n",
       " 'valued',\n",
       " 'store',\n",
       " 'tired',\n",
       " 'bslvyl',\n",
       " 'mayb',\n",
       " 'sell',\n",
       " 'almost',\n",
       " 'sex',\n",
       " 'paper',\n",
       " 'press',\n",
       " 'side',\n",
       " 'area',\n",
       " 'sk',\n",
       " 'currently',\n",
       " 'couple',\n",
       " 'txts',\n",
       " 'computer',\n",
       " 'rock',\n",
       " 'invited',\n",
       " 'felt',\n",
       " 'as',\n",
       " 'ago',\n",
       " 'download',\n",
       " 'india',\n",
       " 'lost',\n",
       " 'mah',\n",
       " 'christmas',\n",
       " 'talking',\n",
       " 'reading',\n",
       " 'load',\n",
       " 'motorola',\n",
       " 'park',\n",
       " 'shower',\n",
       " 'bill',\n",
       " 'hospital',\n",
       " 'askd',\n",
       " 'picking',\n",
       " 'charged',\n",
       " 'photo',\n",
       " 'direct',\n",
       " 'heard',\n",
       " 'return',\n",
       " 'rental',\n",
       " 'eye',\n",
       " 'via',\n",
       " 'darren',\n",
       " 'confirm',\n",
       " 'semester',\n",
       " 'correct',\n",
       " 'reveal',\n",
       " 'red',\n",
       " 'doin',\n",
       " 'ac',\n",
       " 'laptop',\n",
       " 'xy',\n",
       " 'supposed',\n",
       " 'wow',\n",
       " 'sort',\n",
       " 'ugh',\n",
       " 'extra',\n",
       " 'information',\n",
       " 'bcoz',\n",
       " 'kid',\n",
       " 'gym',\n",
       " 'swing',\n",
       " 'redeemed',\n",
       " 'surprise',\n",
       " 'seen',\n",
       " 'difficult',\n",
       " 'through',\n",
       " 'ge',\n",
       " 'promise',\n",
       " 'met',\n",
       " 'max',\n",
       " 'sending',\n",
       " 'lady',\n",
       " 'complimentary',\n",
       " 'comp',\n",
       " 'figure',\n",
       " 'ipod',\n",
       " 'gotta',\n",
       " 'grin',\n",
       " 'ish',\n",
       " 'abiola',\n",
       " 'slowly',\n",
       " 'ex',\n",
       " 'whenever',\n",
       " 'discount',\n",
       " 'lovable',\n",
       " 'yep',\n",
       " 'muz',\n",
       " 'request',\n",
       " 'std',\n",
       " 'bath',\n",
       " 'police',\n",
       " 'hg',\n",
       " 'crave',\n",
       " 'usf',\n",
       " 'safe',\n",
       " 'reward',\n",
       " 'nobody',\n",
       " 'eg',\n",
       " 'orchard',\n",
       " 'road',\n",
       " 'kate',\n",
       " 'wine',\n",
       " 'comin',\n",
       " 'slow',\n",
       " 'weed',\n",
       " 'link',\n",
       " 'asap',\n",
       " 'truth',\n",
       " 'wap',\n",
       " 'fantasy',\n",
       " 'study',\n",
       " 'fact',\n",
       " 'loved',\n",
       " 'loan',\n",
       " 'cheer',\n",
       " 'small',\n",
       " 'somebody',\n",
       " 'page',\n",
       " 'rest',\n",
       " 'laugh',\n",
       " 'rply',\n",
       " 'hmv',\n",
       " 'joke',\n",
       " 'leaf',\n",
       " 'entered',\n",
       " 'txting',\n",
       " 'blood',\n",
       " 'wana',\n",
       " 'idea',\n",
       " 'noon',\n",
       " 'clean',\n",
       " 'dogging',\n",
       " 'door',\n",
       " 'checking',\n",
       " 'asking',\n",
       " 'train',\n",
       " 'own',\n",
       " 'remove',\n",
       " 'lover',\n",
       " 'monday',\n",
       " 'save',\n",
       " 'rent',\n",
       " 'pete',\n",
       " 'member',\n",
       " 'energy',\n",
       " 'nah',\n",
       " 'deal',\n",
       " 'near',\n",
       " 'del',\n",
       " 'forever',\n",
       " 'mistake',\n",
       " 'cup',\n",
       " 'copy',\n",
       " 'normal',\n",
       " 'somewhere',\n",
       " 'men',\n",
       " 'england',\n",
       " 'la',\n",
       " 'opinion',\n",
       " 'situation',\n",
       " 'em',\n",
       " 'cheap',\n",
       " 'warm',\n",
       " 'hoping',\n",
       " 'empty',\n",
       " 'across',\n",
       " 'hw',\n",
       " 'woke',\n",
       " 'usual',\n",
       " 'rakhesh',\n",
       " 'callertune',\n",
       " 'spend',\n",
       " 'med',\n",
       " 'gave',\n",
       " 'cover',\n",
       " 'write',\n",
       " 'short',\n",
       " 'bb',\n",
       " 'tonite',\n",
       " 'ringtones',\n",
       " 'bathe',\n",
       " 'water',\n",
       " 'different',\n",
       " 'representative',\n",
       " 'sony',\n",
       " 'ho',\n",
       " 'ntt',\n",
       " 'voice',\n",
       " 'king',\n",
       " 'merry',\n",
       " 'gap',\n",
       " 'poor',\n",
       " 'fantastic',\n",
       " 'booked',\n",
       " 'oops',\n",
       " 'wc',\n",
       " 'gettin',\n",
       " 'bag',\n",
       " 'admirer',\n",
       " 'getzed',\n",
       " 'ldn',\n",
       " 'kick',\n",
       " 'less',\n",
       " 'immediately',\n",
       " 'glad',\n",
       " 'summer',\n",
       " 'wishing',\n",
       " 'street',\n",
       " 'teach',\n",
       " 'cr',\n",
       " 'otherwise',\n",
       " 'worried',\n",
       " 'doctor',\n",
       " 'sale',\n",
       " 'il',\n",
       " 'convey',\n",
       " 'custcare',\n",
       " 'indian',\n",
       " ...]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To Get All the Vocabulary\n",
    "model.wv.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5569"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('all', 0.9987132549285889),\n",
       " ('morning', 0.9986185431480408),\n",
       " ('wa', 0.9986022114753723),\n",
       " ('well', 0.9985482692718506),\n",
       " ('night', 0.9985289573669434),\n",
       " ('and', 0.9984815716743469),\n",
       " ('day', 0.9983869791030884),\n",
       " ('about', 0.9983753561973572),\n",
       " ('oh', 0.998335063457489),\n",
       " ('dear', 0.9983237981796265)]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go',\n",
       " 'until',\n",
       " 'jurong',\n",
       " 'point',\n",
       " 'crazy',\n",
       " 'available',\n",
       " 'only',\n",
       " 'in',\n",
       " 'bugis',\n",
       " 'great',\n",
       " 'world',\n",
       " 'la',\n",
       " 'buffet',\n",
       " 'cine',\n",
       " 'there',\n",
       " 'got',\n",
       " 'amore',\n",
       " 'wat']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word2vec(doc):\n",
    "    # remove out-of-vocabulary words\n",
    "    # to find the average of all the words vector in the line \n",
    "    return np.mean([model.wv[word] for word in doc if word in model.wv.index_to_key],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5569 [00:00<?, ?it/s]C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 5569/5569 [00:01<00:00, 4739.22it/s]\n"
     ]
    }
   ],
   "source": [
    "#apply for the entire sentences\n",
    "import numpy as np\n",
    "X=[]\n",
    "for i in tqdm(range(len(words))):\n",
    "    X.append(avg_word2vec(words[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5569"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dependent Features\n",
    "## Output Features\n",
    "y = messages[list(map(lambda x: len(x)>0 ,corpus))]\n",
    "y=pd.get_dummies(y['label'])\n",
    "y=y.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5569,)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].reshape(1,-1).shape\n",
    "# create the array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_3092\\3366091579.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, temp_df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#this is the final independent features\n",
    "df = pd.DataFrame()\n",
    "for i in range(0, len(X)):\n",
    "    # Create a DataFrame from the reshaped array\n",
    "    temp_df = pd.DataFrame(X[i].reshape(1, -1))\n",
    "    # Concat the temporary DataFrame with the main DataFrame\n",
    "    # Pass a list containing the DataFrames to concat\n",
    "    df = pd.concat([df, temp_df], ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Independent Feature\n",
    "X=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classifier.fit(X_train,y_train)\n",
    "# Convert feature names to strings before fitting the model\n",
    "X_train.columns = X_train.columns.astype(str)\n",
    "\n",
    "# Now fit the model with the updated feature names\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred=classifier.predict(X_test)# Convert all column names to strings before prediction\n",
    "X_test.columns = X_test.columns.astype(str)\n",
    "\n",
    "# Now make the prediction\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00       144\n",
      "        True       1.00      1.00      1.00       968\n",
      "\n",
      "    accuracy                           1.00      1112\n",
      "   macro avg       1.00      1.00      1.00      1112\n",
      "weighted avg       1.00      1.00      1.00      1112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
